{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7717380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb11da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a494fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "db75656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle up the words\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15d4584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca5ddc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a413d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "  \n",
    "  # -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "  \n",
    "  # -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4e1dbd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22a31a1cf10>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c405b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False),BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False),BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False),BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "25248f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0, 13,  9, 12,  9,  1],\n",
       "        [ 0,  0,  0,  1, 22,  1, 12, 25],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, 10],\n",
       "        [ 0,  0,  0,  0, 11,  8, 25, 14]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5943c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 10)\n",
      "FlattenConsecutive : (4, 4, 20)\n",
      "Linear : (4, 4, 68)\n",
      "BatchNorm1d : (4, 4, 68)\n",
      "Tanh : (4, 4, 68)\n",
      "FlattenConsecutive : (4, 2, 136)\n",
      "Linear : (4, 2, 68)\n",
      "BatchNorm1d : (4, 2, 68)\n",
      "Tanh : (4, 2, 68)\n",
      "FlattenConsecutive : (4, 136)\n",
      "Linear : (4, 68)\n",
      "BatchNorm1d : (4, 68)\n",
      "Tanh : (4, 68)\n",
      "Linear : (4, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9cae9ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a5884953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 20])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randn(4, 8, 10)\n",
    "e.view(4, 4, 20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6fceb62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3073\n",
      "  10000/ 200000: 2.2207\n",
      "  20000/ 200000: 2.2340\n",
      "  30000/ 200000: 1.9008\n",
      "  40000/ 200000: 2.0213\n",
      "  50000/ 200000: 2.3486\n",
      "  60000/ 200000: 2.2185\n",
      "  70000/ 200000: 2.1381\n",
      "  80000/ 200000: 2.0533\n",
      "  90000/ 200000: 2.2031\n",
      " 100000/ 200000: 1.8168\n",
      " 110000/ 200000: 1.5980\n",
      " 120000/ 200000: 2.1361\n",
      " 130000/ 200000: 2.1450\n",
      " 140000/ 200000: 1.6706\n",
      " 150000/ 200000: 1.6708\n",
      " 160000/ 200000: 2.1105\n",
      " 170000/ 200000: 1.6538\n",
      " 180000/ 200000: 2.0229\n",
      " 190000/ 200000: 2.0059\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model (Xb)\n",
    "  loss = F.cross_entropy(logits, Yb)\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update: simple SGD\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5adbd020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22a357f4460>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0ad538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d2306a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.910576343536377\n",
      "val 2.0170745849609375\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1859be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wlihman.\n",
      "stentar.\n",
      "jaslau.\n",
      "aleki.\n",
      "fayil.\n",
      "rometh.\n",
      "rynnlee.\n",
      "abellah.\n",
      "sontie.\n",
      "abrier.\n",
      "ledwi.\n",
      "kalypar.\n",
      "layler.\n",
      "zellah.\n",
      "anjah.\n",
      "dmirah.\n",
      "hozes.\n",
      "siyana.\n",
      "pende.\n",
      "breline.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc340d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
